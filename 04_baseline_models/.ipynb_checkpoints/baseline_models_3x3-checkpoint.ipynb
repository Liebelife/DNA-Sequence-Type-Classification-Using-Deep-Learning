{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "6ffd5d7c-a6bc-44ea-9fc5-2210f3b82972",
   "metadata": {},
   "source": [
    "# Modely 3x3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d0790e35-3b42-4541-878e-b604f3922e1a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/lieberze/DP/Thesis/04_baseline\n"
     ]
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%reload_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "import os\n",
    "import IPython\n",
    "import joblib\n",
    "import pickle\n",
    "\n",
    "import pandas as pd \n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier\n",
    "from sklearn.linear_model import RidgeClassifier,LogisticRegression\n",
    "from xgboost.sklearn import XGBClassifier\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "# from sklearn.kernel_ridge import KernelRidge\n",
    "# from sklearn.svm import SVC\n",
    "# from sklearn.linear_model import SGDClassifier\n",
    "\n",
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "\n",
    "from keras.preprocessing.sequence import pad_sequences\n",
    "from sklearn.model_selection import train_test_split, KFold, cross_val_score\n",
    "from sklearn.metrics import accuracy_score, f1_score\n",
    "from sklearn import metrics\n",
    "from yellowbrick.classifier import ROCAUC\n",
    "from scipy.stats import reciprocal, uniform\n",
    "\n",
    "RANDOM_STATE = 42\n",
    "\n",
    "import os\n",
    "\n",
    "import sys \n",
    "sys.path.insert(0, \"./../\" )\n",
    "from my_classes import ClassificationMetrics\n",
    "\n",
    "print(os.getcwd())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7184c86c-04da-463d-8710-bb5c070d149e",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Tokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "56c9a6ce-092a-4cd2-a95b-ab2d73bf65b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "suffix = \"3x3\"\n",
    "TokenizerAlgorithm = \"BLBPE\" # else \"CharBPE\"\n",
    "\n",
    "if suffix == \"3x3\":\n",
    "    CATEGORIES = ['exon', 'intergenic','intron']\n",
    "elif suffix == \"2x2\":\n",
    "    CATEGORIES = ['exon', 'other']\n",
    "    \n",
    "ResultsFolder = \"Models_and_Results\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e0fe4085-2396-415e-a117-b1a4252c0b7c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "file /home/lieberze/DP/Thesis/02_tokenizery_new_data/02_ByteLevelBPE/All_genomes_sample/All_512/5000/config.json not found\n"
     ]
    }
   ],
   "source": [
    "RootFolder = \"/home/lieberze/DP/Thesis/\"\n",
    "\n",
    "TokenizerFolder = \"02_tokenizery_new_data\"\n",
    "if TokenizerAlgorithm == \"BLBPE\":\n",
    "    Name = \"02_ByteLevelBPE\"\n",
    "elif TokenizerAlgorithm == \"CharBPE\":\n",
    "    Name = \"01_CharBPE\"    \n",
    "FolderName = \"All_genomes_sample\"\n",
    "Length = \"All_512\"\n",
    "Size = \"5000\"\n",
    "All_512_BLBPE = os.path.abspath(os.path.join(RootFolder, f'{TokenizerFolder}/{Name}/{FolderName}/{Length}/{Size}'))\n",
    "\n",
    "from transformers import RobertaTokenizer\n",
    "tokenizer = RobertaTokenizer.from_pretrained(All_512_BLBPE)\n",
    "# tokenizer"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "816d0f1c-9d0a-4dd6-9b82-c5aaaf54b8dd",
   "metadata": {},
   "source": [
    "## Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d60161e6-7e6a-4dd8-9f8f-ab524ac5e00a",
   "metadata": {},
   "outputs": [],
   "source": [
    "TokenizerName = \"BLBPE\"\n",
    "\n",
    "RootFolder = \"/home/lieberze/DP/Thesis/\"\n",
    "Baseline = os.path.abspath(os.path.join(RootFolder, \"04_baseline\"))\n",
    "DataFolder = os.path.abspath(os.path.join(Baseline, \"data\"))\n",
    "TestFolder = os.path.abspath(os.path.join(DataFolder, \"test\"))\n",
    "TrainFolder = os.path.abspath(os.path.join(DataFolder, \"train\"))\n",
    "\n",
    "if suffix == \"3x3\":\n",
    "    TrainFile = os.path.abspath(os.path.join(TrainFolder, \"Train_250k.txt\"))\n",
    "    TestFile = os.path.abspath(os.path.join(TestFolder, \"Test_holdout_150k.txt\"))\n",
    "elif suffix == \"2x2\":\n",
    "    TrainFile = os.path.abspath(os.path.join(TrainFolder, \"2x2_train_200k.txt\"))\n",
    "    TestFile = os.path.abspath(os.path.join(TestFolder, \"2x2_test_100k.txt\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "9c413fc2-09ac-46ea-b715-4407957f69fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ! head $TrainFile\n",
    "# print(\"kontrola vyvazenosti datasetu\")\n",
    "# print(\"train file:\")\n",
    "# ! cat $TrainFile | cut -f1 | sort | uniq -c\n",
    "# print(\"test file:\")\n",
    "# ! cat $TestFile | cut -f1 | sort | uniq -c"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dc097ab1-436c-4df9-b4a2-3ccda62171d5",
   "metadata": {},
   "source": [
    "## Encode - pouze jednou"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "46eaa35f-9742-4b64-8ee8-12438bfad24c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def encode(FileToEncodePath, EncodedFilesPath, Tokenizer):\n",
    "    with open(FileToEncodePath, \"r\") as file_in,\\\n",
    "        open(EncodedFilesPath + f\"/encoded_{suffix}.txt\", \"w\") as file_out:\n",
    "        for Line in file_in:\n",
    "            LineSplit = Line.strip().split()\n",
    "            SeqType, Seq = LineSplit[0], LineSplit[-1]\n",
    "            Encoded = Tokenizer.encode(Seq, max_length=128, padding=\"max_length\", truncation=True)\n",
    "            file_out.write(SeqType + \"\\t\" + str(Encoded) + \"\\n\")\n",
    "            \n",
    "# encode(TrainFile, TrainFolder, tokenizer)\n",
    "# encode(TestFile, TestFolder, tokenizer)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0ed4bc08-cc88-4ba6-9ea9-18d356e6ee07",
   "metadata": {},
   "source": [
    "## Nacist a ztokenizovat, dat do dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "b2760ff8-60f4-4795-a9b4-43313b01c7f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def LoadData(Path):\n",
    "    SeqTypes, Ids = [], []\n",
    "    with open(Path, \"r\") as file:\n",
    "        for line in file:\n",
    "            s, i = line.strip().split(\"\\t\")\n",
    "            i = np.array(i.strip(\"[]\").split(\", \")).reshape(-1,1)\n",
    "            SeqTypes.append(s), Ids.append(i)\n",
    "            \n",
    "    # adds 1 (for both algorithms it is the id of the <pad> token, post == at the end\n",
    "    X = pad_sequences(Ids, value=1, padding='post')\n",
    "    nsamples, nx, ny = X.shape\n",
    "    X = X.reshape((nsamples,nx*ny)) # from 3 to 2 dimensions\n",
    "    y = np.array(SeqTypes)            \n",
    "    return X, y\n",
    "\n",
    "def PickBest(BestScores):    \n",
    "    top_model = sorted(BestScores, key=lambda x: x[0], reverse=True)[0]\n",
    "    # load model with best params\n",
    "    validation_score, model, params = top_model\n",
    "    model.set_params(**params)\n",
    "    print(model)\n",
    "    print(\"validation f1_score (weighted):\", validation_score)\n",
    "    model = model.fit(X_train, y_train)\n",
    "    return model\n",
    "      \n",
    "def FitPredictGetMetrics(model, X_test, y_test, PathToSave, TitleName):\n",
    "    y_pred = model.predict(X_test)\n",
    "    \n",
    "    # metrics \n",
    "    # acc_score = accuracy_score(y_test, y_pred)\n",
    "    f1 = f1_score(y_test, y_pred, average='weighted')\n",
    "    cm = metrics.confusion_matrix(y_test, y_pred, normalize='true')\n",
    "    report = metrics.classification_report(y_test, y_pred, digits=2, output_dict=True, zero_division=0)\n",
    "    # metrics.plot_confusion_matrix(model, X_test, y_test) \n",
    "    \n",
    "    print(\"test f1_score (weighted):\", f1)\n",
    "    \n",
    "    # report table (f1, precision, recall)\n",
    "    df_report = pd.DataFrame(report).transpose()\n",
    "    df_report.to_pickle(PathToSave + f\"/report_{suffix}.pkl\")\n",
    "    weighted_F1_average = df_report[\"f1-score\"][\"weighted avg\"]\n",
    "    print(df_report)\n",
    "    \n",
    "    # # confusion matrix\n",
    "    # plt.figure(figsize=(8, 6))\n",
    "    # df_cm = pd.DataFrame(cm)\n",
    "    # df_cm.columns = CATEGORIES # ['exon', 'intergenic','intron'] or [\"exon\", \"other\"]\n",
    "    # df_cm.index = CATEGORIES\n",
    "    # plt.title('Confusion Matrix, normalized', size=16)\n",
    "    # sns.heatmap(df_cm, annot=True, cmap='Blues')\n",
    "    # plt.savefig(PathToSave + f'/confusion_matrix_{suffix}.png', transparent=False, dpi=80, bbox_inches=\"tight\")\n",
    "    # plt.show()    \n",
    "    \n",
    "    CMName = PathToSave + f'/confusion_matrix_{suffix}.png'\n",
    "    ClassificationMetrics.ConfMatrix(y_test, y_pred, CATEGORIES, TitleName, CMName)\n",
    "    return weighted_F1_average\n",
    "\n",
    "def ROCAUCcurve(model, X_train, y_train, X_test, y_test, PathToSave):\n",
    "    visualizer = ROCAUC(model, classes=CATEGORIES)\n",
    "    visualizer.fit(X_train, y_train)        # Fit the training data to the visualizer\n",
    "    visualizer.score(X_test, y_test)        # Evaluate the model on the test data\n",
    "    plt.savefig(PathToSave + f'/ROC_curve_{suffix}.png', transparent=False, dpi=80, bbox_inches=\"tight\")\n",
    "    visualizer.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "9456053c-ceba-46f1-ab90-57ddc5b0aeac",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_grid = {    \n",
    "    # https://medium.com/all-things-ai/in-depth-parameter-tuning-for-random-forest-d67bb7e920d\n",
    "    RandomForestClassifier(n_jobs=-1, random_state=RANDOM_STATE): {\n",
    "            \"n_estimators\": [150, 200, 400],\n",
    "            \"max_depth\": [1, 3, 5, 7, 9],\n",
    "            \"criterion\": [\"gini\", \"entropy\"],\n",
    "            \"min_samples_split\": [0.6, 0.8, 2, 4],\n",
    "            \"min_samples_leaf\": [0.4, 1, 2, 4, 10, 15]\n",
    "        },    \n",
    "    # https://www.analyticsvidhya.com/blog/2016/02/complete-guide-parameter-tuning-gradient-boosting-gbm-python/\n",
    "    GradientBoostingClassifier(max_features = 'sqrt', subsample = 0.8, random_state=RANDOM_STATE): {\n",
    "            \"min_samples_split\": [3000, 4000, 5000, 6000],\n",
    "            \"min_samples_leaf\": [50, 100, 150, 200],\n",
    "            \"max_depth\": [5, 6, 7, 8]\n",
    "        },        \n",
    "    RidgeClassifier(random_state=RANDOM_STATE): {\n",
    "            \"alpha\": [1e-3, 1e-2, 1e-1, 1]\n",
    "            },    \n",
    "    # https://datascience.stackexchange.com/questions/36049/how-to-adjust-the-hyperparameters-of-mlp-classifier-to-get-more-perfect-performa\n",
    "    MLPClassifier(random_state=RANDOM_STATE, max_iter=300): { # trenuje se dlouho (?)\n",
    "            'hidden_layer_sizes': [(100,50), (100,50, 100), (100,100,1000), (100,), (200,)], # uzpusobit velikosti vstupniho vektoru\n",
    "            'activation': ['tanh', 'relu'],\n",
    "            'solver': ['sgd', 'adam'],\n",
    "            'alpha': [0.0001, 0.001, 0.005, 0.05],\n",
    "            'learning_rate': ['constant','adaptive'],\n",
    "            'early_stopping': [True, False],\n",
    "    },\n",
    "    LogisticRegression(random_state=RANDOM_STATE): {\n",
    "        'penalty' : ['none', 'l1', 'l2'],\n",
    "        'solver': ['newton-cg', 'lbfgs', 'liblinear'],\n",
    "        'C' : [100, 10, 1.0, 0.1, 0.01],\n",
    "    },\n",
    "    # https://www.analyticsvidhya.com/blog/2016/03/complete-guide-parameter-tuning-xgboost-with-codes-python/\n",
    "    # https://stats.stackexchange.com/questions/243908/tuning-order-xgboost/386794#386794\n",
    "    XGBClassifier(random_state=RANDOM_STATE, n_jobs=-1, n_estimators=100): { # Lower the learning rate and decide the optimal parameters\n",
    "        \"booster\": [\"gbtree\"],# , \"gblinear\",\"dart\"],\n",
    "        \"learning_rate\": [0.3, 0.1, 0.01, 0.05], # Choose a relatively high learning rate\n",
    "        \"max_depth\": [5, 6, 8, 10], # Tune tree-specific parameters (max_depth, min_child_weight, gamma, subsample, colsample_bytree)\n",
    "                        # This should be between 3-10\n",
    "        \"gamma\" :  [0, 0.1, 0.2],\n",
    "        \"colsample_bytree\": [0.4, 0.5, 0.6, 0.7],\n",
    "        'colsample_bylevel': [0.6, 0.7, 0.8, 0.9, 1.0],\n",
    "        'min_child_weight': [0.5, 1.0, 3.0, 5.0, 7.0, 10.0, 12.0],\n",
    "        \"subsample\" : [0.6, 0.7, 0.9],\n",
    "        \"reg_lambda\": [0.05, 0.1, 1.0], # Tune regularization parameters (lambda, alpha)        \n",
    "    }\n",
    "#     SVC(random_state=RANDOM_STATE): { # bezi extremne dlouho\n",
    "#         \"kernel\":['linear', 'rbf', 'poly'],\n",
    "#         \"gamma\": reciprocal(0.001, 0.1),\n",
    "#         \"C\": uniform(1, 10),\n",
    "#         \"degree\": [0, 1, 2, 3, 4, 5, 6]\n",
    "#     }\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "7e71d3f2-be54-4d2d-8211-8cd6c12d2e1b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def TryClassifier(model, grid, X_train, y_train):\n",
    "    kf = KFold(n_splits=10, random_state=RANDOM_STATE, shuffle=True)\n",
    "    model = RandomizedSearchCV(estimator=model, \n",
    "                               param_distributions=grid,\n",
    "                               n_iter=5, \n",
    "                               cv=kf,\n",
    "                               verbose=1, \n",
    "                               n_jobs=-1,\n",
    "                               random_state=RANDOM_STATE, \n",
    "                               scoring = [\"f1_weighted\", \"accuracy\", \"precision_weighted\", \"recall_weighted\"], # acc, recall, precision\n",
    "                               refit = \"f1_weighted\", # has to be set to the metric according to which the best params fit\n",
    "                               return_train_score=True\n",
    "                              )\n",
    "    model.fit(X_train, y_train)  \n",
    "    # vracet jeste mean, std\n",
    "    # best_score = model.best_score_ \n",
    "    # best_index = model.best_index_\n",
    "    # best_params = model.best_estimator_.get_params()\n",
    "    # BestScore = {\"best_score\": best_score, \"best_score\": best_params, \"best_score\": best_index}\n",
    "    return model.best_estimator_, model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "af2638f0-95f9-4993-99f2-db9407d2bab1",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "TODO:\n",
    "- https://stackoverflow.com/questions/45915247/sklearn-randomizedsearchcv-extract-confusion-matrix-for-different-folds\n",
    "- https://towardsdatascience.com/how-to-plot-a-confusion-matrix-from-a-k-fold-cross-validation-b607317e9874"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "c1f754ea-3d72-4341-9ec2-dc2ff0cd46c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# model_grid = {i:model_grid[i] for x,i in enumerate(model_grid) if x == 4 or x ==5 }\n",
    "# model_grid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "9f2d3ad3-0170-4888-87e7-66796ca5a13b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load Data\n",
    "X_train, y_train = LoadData(TrainFolder + f\"/{TokenizerName}/encoded_{suffix}.txt\")\n",
    "X_test, y_test = LoadData(TestFolder + f\"/{TokenizerName}/encoded_{suffix}.txt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "7d4b2e0d-3628-4a68-a46b-f57f26ec1e27",
   "metadata": {},
   "outputs": [],
   "source": [
    "# X_train, y_train, X_test, y_test= X_train[:1000], y_train[:1000], X_test[:1000], y_test[:1000]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cc4dd8f5-2c4a-4cd0-8887-0a53838dc4ed",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 10 folds for each of 5 candidates, totalling 50 fits\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "for model, grid in model_grid.items():\n",
    "    ModelFolderName = str(model).split(\"(\")[0]    \n",
    "    BestEstimator, Model = TryClassifier(model, grid, X_train, y_train)\n",
    "    \n",
    "    # save files to:\n",
    "    Path = f\"./{ResultsFolder}/{TokenizerAlgorithm}/{ModelFolderName}\"\n",
    "    \n",
    "    # create a folder if it doesn't already exist\n",
    "    !mkdir -p {Path}\n",
    "    \n",
    "    # save best model\n",
    "    filename = f'/classification_model_{suffix}.sav'\n",
    "    joblib.dump(BestEstimator, Path + filename)\n",
    "    \n",
    "    # save whole model with cv scores\n",
    "    with open(f\"{Path}/ModelScores_{suffix}.pk\", 'wb') as f:\n",
    "        pickle.dump(Model, f)\n",
    "        \n",
    "    # results and confusion matrix\n",
    "    sns.set(font_scale=1.2)    \n",
    "    FitPredictGetMetrics(BestEstimator, X_test, y_test, Path, ModelFolderName)\n",
    "    \n",
    "    # ROC AUC curve\n",
    "    if suffix == \"3x3\":\n",
    "        sns.set(font_scale=1.2)    \n",
    "        ROCAUCcurve(BestEstimator, X_train, y_train, X_test, y_test, Path)           "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a062eba1-76d6-402b-9e57-60211502debd",
   "metadata": {},
   "source": [
    "## Pak nějak pohrotit ty výsledky:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "386a6319-caa1-4ff2-a8a5-b9576d6dacbb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# for model, grid in model_grid.items():\n",
    "#     ModelFolderName = str(model).split(\"(\")[0] \n",
    "    # Path = f\"./{ResultsFolder}/{TokenizerAlgorithm}/{ModelFolderName}\"\n",
    "    # with open(f\"{Path}/model_{suffix}.pk\", 'rb') as f:\n",
    "    #     Model = pickle.load(f)\n",
    "    # d = ['mean_test_f1_weighted','std_test_f1_weighted',\n",
    "    #     'mean_test_accuracy','std_test_f1_weighted',\n",
    "    #     'mean_test_precision_weighted','std_test_f1_weighted',\n",
    "    #     'mean_test_recall_weighted','std_test_f1_weighted']\n",
    "    # for metric_name in d:\n",
    "    #     result = Model.cv_results_[metric_name][Model.best_index_]\n",
    "    #     print(metric_name, \":\", result)\n",
    "    \n",
    "# no a tohle nejak do tabulky"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bfc35566-2907-4b74-a6e3-42078c9b4551",
   "metadata": {},
   "outputs": [],
   "source": [
    "# from PIL import Image\n",
    "# for model in model_grid.keys():\n",
    "#     ModelFolderName = str(model).split(\"(\")[0]   \n",
    "#     Path = f\"./{ResultsFolder}/{TokenizerAlgorithm}/{ModelFolderName}\"\n",
    "#     with open(Path + f'/report_{suffix}.pkl', 'rb') as f:\n",
    "#         report = pickle.load(f)\n",
    "#     # print(report)\n",
    "#     print(ModelFolderName, round(report[\"f1-score\"][\"weighted avg\"],2))\n",
    "     \n",
    "#     conf_m = Image.open(Path + f'/confusion_matrix_{suffix}.png')\n",
    "#     # roc = Image.open(Path + '/ROC_curve_3x3.png')\n",
    "    \n",
    "#     conf_m.show()\n",
    "#     # roc.show() "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7ce5b4e5-2d94-4a2a-819b-c6d34c1d1323",
   "metadata": {},
   "source": [
    "tady asi teda ještě CV na train datech - cf matrix\n",
    "- X_train, y_train\n",
    "- udelat kfolds\n",
    "- pro kazdy vypsat cf matrix"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
