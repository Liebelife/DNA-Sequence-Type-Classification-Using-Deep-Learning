{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "48c0f312-3f7d-4f05-bcae-25a7b12a0a3e",
   "metadata": {},
   "source": [
    "# ML classification\n",
    "- load tokenizers\n",
    "- tokenize data\n",
    "- load data, split into train, test\n",
    "- pick classifier (by running multiple tests)\n",
    "- predict on test data (to determine the accuracy)\n",
    "- pick the best vocabulary (tokenizer) to use\n",
    "\n",
    "\n",
    "https://huggingface.co/transformers/preprocessing.html"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6d895c19-d8c0-4c5d-9afb-25a4cc41401f",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Imports and Paths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "ab8eae48-3bad-4504-bb2b-ab8cddc10240",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import IPython\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from tokenizers import CharBPETokenizer\n",
    "from tokenizers import ByteLevelBPETokenizer\n",
    "\n",
    "from sklearn.model_selection import train_test_split, KFold, cross_val_score\n",
    "from sklearn.metrics import accuracy_score, f1_score\n",
    "from sklearn import metrics\n",
    "from keras.preprocessing.sequence import pad_sequences\n",
    "\n",
    "from yellowbrick.classifier import ROCAUC\n",
    "\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.kernel_ridge import KernelRidge\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from scipy.stats import uniform\n",
    "\n",
    "from hpsklearn import HyperoptEstimator\n",
    "\n",
    "RANDOM_STATE = 42"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "17fec715-9636-4cef-89fe-1b1e4a11373d",
   "metadata": {},
   "outputs": [],
   "source": [
    "RootFolder = \"/home/lieberze/DP/Thesis/\"\n",
    "\n",
    "DataFolder = os.path.abspath(os.path.join(RootFolder, 'model_training/data/512_bp_for_encoding/NEW/'))\n",
    "FileToEncode_1M = os.path.abspath(os.path.join(DataFolder, 'All_1M.txt'))\n",
    "# FileToEncode_3M = os.path.abspath(os.path.join(DataFolder, 'All_3M.txt'))\n",
    "\n",
    "AttemptFolder = os.path.abspath(os.path.join(RootFolder, \"tokenizery_new_data/\"))\n",
    "EncodedFolder_1M = os.path.abspath(os.path.join(AttemptFolder, \"data/sample/Encoding/Encoded_512bp_1M_lines/NEW/\"))\n",
    "\n",
    "FolderName = \"All_genomes_sample\"\n",
    "name = \"01_CharBPE\"\n",
    "CharBPE = os.path.abspath(os.path.join(AttemptFolder, f'{name}/{FolderName}'))\n",
    "All_512_BPE = os.path.abspath(os.path.join(CharBPE, 'All_512/'))\n",
    "name = \"02_ByteLevelBPE\"\n",
    "ByteLevelBPE = os.path.abspath(os.path.join(AttemptFolder, f'{name}/{FolderName}'))\n",
    "All_512_BLBPE = os.path.abspath(os.path.join(ByteLevelBPE, 'All_512/'))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ca40b9a6-1313-4f75-bbc5-f2253109620b",
   "metadata": {},
   "source": [
    "## Tokenize Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "a7dca7e9-1cec-490a-b4b3-a3fdc98b9e11",
   "metadata": {},
   "outputs": [],
   "source": [
    "def LoadTokenizer(TokenizerPath, Tokenizer):\n",
    "    vocab = f\"{TokenizerPath}/vocab.json\"\n",
    "    merges = f\"{TokenizerPath}/merges.txt\"\n",
    "    tokenizer = Tokenizer(vocab, merges)    \n",
    "    return tokenizer\n",
    "\n",
    "def ModifyPath(TokenizerPath, TokenizerName, FolderForEncoded):\n",
    "    EncodedPath = TokenizerPath.strip(\"/\").split(\"/\")[-2:]\n",
    "    EncodedPath = TokenizerName + \"/\" + \"/\".join(EncodedPath)\n",
    "    EncodedPath = os.path.abspath(os.path.join(FolderForEncoded, EncodedPath))\n",
    "    return EncodedPath\n",
    "\n",
    "def EncodeFile(TokenizerPath, Tokenizer, FileToEncodePath, EncodedFilesPath):\n",
    "    !mkdir -p {EncodedFilesPath}\n",
    "    print(EncodedFilesPath)\n",
    "    Tokenizer = LoadTokenizer(TokenizerPath, Tokenizer)\n",
    "    unk = 0\n",
    "    with open(FileToEncodePath, \"r\") as file_in,\\\n",
    "        open(EncodedFilesPath + \"/encoded.txt\", \"w\") as file_out:\n",
    "        for Line in file_in:\n",
    "            LineSplit = Line.strip().split()\n",
    "            SeqType, Seq = LineSplit[0], LineSplit[-1]\n",
    "            Encoded = Tokenizer.encode(Seq)    \n",
    "            if \"<unk>\" in Encoded.tokens:\n",
    "                 unk += 1\n",
    "            file_out.write(SeqType + \"\\t\" + str(Encoded.ids) + \"\\n\")\n",
    "    print(f\"There are {unk} unk tokens in this file\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ffa6381d-794b-4576-99ab-cad965df89cf",
   "metadata": {},
   "source": [
    "Next chunk is commented out since it had to be run only one time.\n",
    "\n",
    "The run output showed that there are no \\<unk> tokens in any of the loaded files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "db322a55-bf54-4744-9593-55c1773e6224",
   "metadata": {},
   "outputs": [],
   "source": [
    "# VocabSizes = [5000, 15000, 50000]\n",
    "# FileToEncode = FileToEncode_1M\n",
    "# FolderForEncoded = EncodedFolder_1M\n",
    "\n",
    "# # TokenizerName = \"CharBPE\"\n",
    "# # Paths = [All_512_BPE]\n",
    "# # Tokenizer = CharBPETokenizer\n",
    "# # for Path in Paths:\n",
    "# #     for Size in VocabSizes:\n",
    "# #         TokenizerPath = f\"{Path}/{Size}/\"\n",
    "# #         EncodedPath = ModifyPath(TokenizerPath, TokenizerName, FolderForEncoded)\n",
    "# #         EncodeFile(TokenizerPath, Tokenizer, FileToEncode, EncodedPath)\n",
    "        \n",
    "# TokenizerName = \"ByteLevelBPE\"\n",
    "# Paths = [All_512_BLBPE]\n",
    "# Tokenizer = ByteLevelBPETokenizer\n",
    "# for Path in Paths:\n",
    "#     for Size in VocabSizes:\n",
    "#         TokenizerPath = f\"{Path}/{Size}/\"\n",
    "#         EncodedPath = ModifyPath(TokenizerPath, TokenizerName, FolderForEncoded)\n",
    "#         EncodeFile(TokenizerPath, Tokenizer, FileToEncode, EncodedPath)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "07648edb-14b0-4b31-ac53-9f62ea92ee1d",
   "metadata": {},
   "source": [
    "Show paths of all the files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "aa80ce0e-edd0-47e3-aa11-f7e2a73e0d26",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/lieberze/DP/Thesis/tokenizery_new_data/data/sample/Encoding/Encoded_512bp_1M_lines/NEW/CharBPE/All_512/5000\n",
      "/home/lieberze/DP/Thesis/tokenizery_new_data/data/sample/Encoding/Encoded_512bp_1M_lines/NEW/CharBPE/All_512/15000\n",
      "/home/lieberze/DP/Thesis/tokenizery_new_data/data/sample/Encoding/Encoded_512bp_1M_lines/NEW/CharBPE/All_512/50000\n",
      "/home/lieberze/DP/Thesis/tokenizery_new_data/data/sample/Encoding/Encoded_512bp_1M_lines/NEW/ByteLevelBPE/All_512/5000\n",
      "/home/lieberze/DP/Thesis/tokenizery_new_data/data/sample/Encoding/Encoded_512bp_1M_lines/NEW/ByteLevelBPE/All_512/15000\n",
      "/home/lieberze/DP/Thesis/tokenizery_new_data/data/sample/Encoding/Encoded_512bp_1M_lines/NEW/ByteLevelBPE/All_512/50000\n"
     ]
    }
   ],
   "source": [
    "Names = [\"CharBPE\", \"ByteLevelBPE\"]\n",
    "BasePairLengths = [\"All_512\"]\n",
    "VocabSizes = [5000, 15000, 50000]\n",
    "\n",
    "Paths = []\n",
    "for Name in Names:\n",
    "    for BasePairLength in BasePairLengths:\n",
    "        for Size in VocabSizes:\n",
    "            Location = Name + \"/\" + BasePairLength + \"/\" + str(Size) + \"/\"\n",
    "            EncodedPath = os.path.abspath(os.path.join(EncodedFolder_1M, Location))\n",
    "            Paths.append(EncodedPath)\n",
    "            print(EncodedPath)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "11fee44e-b2c9-4439-9be1-b8be535b2723",
   "metadata": {},
   "source": [
    "## Pick best model and hyperparameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "0ee330e0-b4ed-412e-8ac1-6013166ba448",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier\n",
    "from sklearn.kernel_ridge import KernelRidge\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.linear_model import RidgeClassifier\n",
    "\n",
    "model_grid = {    \n",
    "    # https://medium.com/all-things-ai/in-depth-parameter-tuning-for-random-forest-d67bb7e920d\n",
    "    RandomForestClassifier(n_jobs=-1, random_state=RANDOM_STATE): {\n",
    "            \"n_estimators\": [150, 200, 400],\n",
    "            \"max_depth\": [1, 3, 5, 7, 9],\n",
    "            \"criterion\": [\"gini\", \"entropy\"],\n",
    "            \"min_samples_split\": [0.6, 0.8, 2, 4],\n",
    "            \"min_samples_leaf\": [0.4, 1, 2, 4, 10, 15]\n",
    "        },    \n",
    "    # https://www.analyticsvidhya.com/blog/2016/02/complete-guide-parameter-tuning-gradient-boosting-gbm-python/\n",
    "    GradientBoostingClassifier(max_features = 'sqrt', subsample = 0.8, random_state=RANDOM_STATE): {\n",
    "            \"min_samples_split\": [3000, 4000, 5000, 6000],\n",
    "            \"min_samples_leaf\": [50, 100, 150, 200],\n",
    "            \"max_depth\": [5, 6, 7, 8]\n",
    "        },        \n",
    "    RidgeClassifier(random_state=RANDOM_STATE): {\n",
    "            \"alpha\": [1e-3, 1e-2, 1e-1, 1]\n",
    "        },    \n",
    "    # # KNN - memory problems\n",
    "    # # It is advised to use the KNN algorithm for multiclass \n",
    "    # # classification if the number of samples of the data is less than 50,000\n",
    "    # KNeighborsClassifier(n_jobs=-1):{\n",
    "    #     \"n_neighbors\": [3, 5, 10, 20, 30],\n",
    "    #     \"leaf_size\": [5, 10, 20, 30, 40],\n",
    "    #     \"metric\": []\n",
    "    # },    \n",
    "    # # https://www.mdelcueto.com/blog/kernel-ridge-regression-tutorial/\n",
    "    # # TerminatedWorkerError: A worker process managed by the executor was unexpectedly terminated.\n",
    "    # # This could be caused by a segmentation fault while calling the function or by an excessive memory\n",
    "    # # usage causing the Operating System to kill the worker.\n",
    "    # KernelRidge(): {\n",
    "    #     \"kernel\": ['poly', 'rbf', 'linear'],\n",
    "    #     \"degree\": [2,3,4,5],\n",
    "    #     \"alpha\": [1e-4, 1e-3, 1e-2, 1e-1, 1]\n",
    "    # }   \n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "b45d2266-50fb-438d-9789-9dc676468bb5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# for path in paths   \n",
    "def LoadData(Path):\n",
    "    SeqTypes, Ids = [], []\n",
    "    with open(Path, \"r\") as file:\n",
    "        for line in file:\n",
    "            s, i = line.strip().split(\"\\t\")\n",
    "            i = np.array(i.strip(\"[]\").split(\", \")).reshape(-1,1)\n",
    "            SeqTypes.append(s), Ids.append(i)\n",
    "            \n",
    "    # adds 1 (for both algorithms it is the id of the <pad> token, post == at the end\n",
    "    X = pad_sequences(Ids, value=1, padding='post')\n",
    "    nsamples, nx, ny = X.shape\n",
    "    X = X.reshape((nsamples,nx*ny)) # from 3 to 2 dimensions\n",
    "    y = np.array(SeqTypes)            \n",
    "    return X, y\n",
    "\n",
    "# https://stackoverflow.com/questions/35388647/how-to-use-gridsearchcv-output-for-a-scikit-prediction\n",
    "# https://stackoverflow.com/questions/64950438/how-does-randomizedsearchcv-decide-what-the-best-parameters-are\n",
    "# RS-CV uses accuracy for classification\n",
    "# https://www.baeldung.com/cs/multi-class-f1-score\n",
    "# The class F-1 scores are averaged by using the number of instances in a class as weights\n",
    "def TryClassifiers(model_grid, random_state, X_train, y_train):\n",
    "    kf = KFold(n_splits=5, random_state=0, shuffle=True)\n",
    "    BestScores = []\n",
    "    for clf, grid in model_grid.items():\n",
    "        model = RandomizedSearchCV(estimator=clf, \n",
    "                                   param_distributions=grid,\n",
    "                                   n_iter=5, \n",
    "                                   cv=kf,\n",
    "                                   verbose=1, \n",
    "                                   n_jobs=-1,\n",
    "                                   random_state=random_state, \n",
    "                                   scoring = \"f1_weighted\",\n",
    "                                  )\n",
    "        model.fit(X_train, y_train)     \n",
    "        best_score = model.best_score_\n",
    "        best_params = model.best_estimator_.get_params()\n",
    "        BestScores.append([best_score, clf, best_params])\n",
    "    return BestScores\n",
    "\n",
    "def PickBest(BestScores):    \n",
    "    top_model = sorted(BestScores, key=lambda x: x[0], reverse=True)[0]\n",
    "    # load model with best params\n",
    "    validation_score, model, params = top_model\n",
    "    model.set_params(**params)\n",
    "    print(model)\n",
    "    print(\"validation f1_score (weighted):\", validation_score)\n",
    "    model = model.fit(X_train, y_train)\n",
    "    return model\n",
    "      \n",
    "def FitPredictGetMetrics(model, X_test, y_test, PathToSave):\n",
    "    y_pred = model.predict(X_test)\n",
    "    \n",
    "    # metrics \n",
    "    # acc_score = accuracy_score(y_test, y_pred)\n",
    "    f1 = f1_score(y_test, y_pred, average='weighted')\n",
    "    cm = metrics.confusion_matrix(y_test, y_pred, normalize='true')\n",
    "    report = metrics.classification_report(y_test,y_pred,digits=2, output_dict=True,zero_division=0)\n",
    "    # metrics.plot_confusion_matrix(model, X_test, y_test) \n",
    "    \n",
    "    print(\"test f1_score (weighted):\", f1)\n",
    "    \n",
    "    # report table (f1, precision, recall)\n",
    "    df_report = pd.DataFrame(report).transpose()\n",
    "    df_report.to_pickle(PathToSave + \"/report.pkl\")\n",
    "    weighted_F1_average = df_report[\"f1-score\"][\"weighted avg\"]\n",
    "    print(df_report)\n",
    "    \n",
    "    # SHOW THE DIFFERENCES\n",
    "    # exon, intron, intergenic = df_report[\"f1-score\"].exon, df_report[\"f1-score\"].intron, df_report[\"f1-score\"].intergenic\n",
    "    # exon_vs_rest_ratio = exon/(intron + intergenic)\n",
    "    # exon_vs_rest_f1_score = exon, intron + intergenic, exon_vs_rest_ratio\n",
    "    \n",
    "    # confusion matrix\n",
    "    plt.figure(figsize=(8, 6))\n",
    "    df_cm = pd.DataFrame(cm)\n",
    "    df_cm.columns = ['exon', 'intergenic','intron']\n",
    "    df_cm.index = ['exon', 'intergenic','intron']\n",
    "    plt.title('Confusion Matrix, normalized', size=16)\n",
    "    sns.heatmap(df_cm, annot=True, cmap='Blues')\n",
    "    plt.savefig(PathToSave + '/confusion_matrix.png', transparent=False, dpi=80, bbox_inches=\"tight\")\n",
    "    plt.show()    \n",
    "      \n",
    "    return weighted_F1_average\n",
    "\n",
    "# https://www.scikit-yb.org/en/latest/api/classifier/index.html    \n",
    "def ROCAUCcurve(model, X_train, y_train, X_test, y_test, PathToSave):\n",
    "    visualizer = ROCAUC(model, classes=[\"exon\", \"intergenic\", \"intron\"])\n",
    "    visualizer.fit(X_train, y_train)        # Fit the training data to the visualizer\n",
    "    visualizer.score(X_test, y_test)        # Evaluate the model on the test data\n",
    "    plt.savefig(PathToSave + '/ROC_curve.png', transparent=False, dpi=80, bbox_inches=\"tight\")\n",
    "    visualizer.show()\n",
    "    \n",
    "#     # Call finalize to draw the final yellowbrick-specific elements\n",
    "#     model.finalize()\n",
    "\n",
    "#     # Get access to the axes object and modify labels\n",
    "#     model.ax.set_xlabel(\"measured concrete strength\")\n",
    "#     model.ax.set_ylabel(\"predicted concrete strength\")\n",
    "#     plt.savefig(\"peplot.pdf\")\n",
    "\n",
    "    # from yellowbrick.classifier import PrecisionRecallCurve\n",
    "    # visualizer = PrecisionRecallCurve(model, classes=[\"exon\", \"intergenic\", \"intron\"])\n",
    "    # visualizer.fit(X_train, y_train)        # Fit the training data to the visualizer\n",
    "    # visualizer.score(X_test, y_test)        # Evaluate the model on the test data\n",
    "    # visualizer.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c25a3c4-b640-4c5c-b517-9ef1fe7f066d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "179cb9d8-0340-4806-828b-62bca3e4f066",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # https://inblog.in/AUC-ROC-score-and-curve-in-multiclass-classification-problems-2ja4jOHb2X\n",
    "\n",
    "# #importing all the necessary libraries\n",
    "# from sklearn.preprocessing import OrdinalEncoder, LabelEncoder\n",
    "# from sklearn.metrics import roc_curve, roc_auc_score\n",
    "\n",
    "# # model.fit(X_tr, y_tr)\n",
    "\n",
    "# # predicting the data\n",
    "# y_pred_cnb = model.predict(X_te)\n",
    "# y_prob_pred_cnb = model.predict_proba(X_te)\n",
    "\n",
    "# #roc auc score\n",
    "# roc_auc_score(y_te, y_prob_pred_cnb, multi_class='ovo', average='weighted')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "b80cf63c-ba90-4744-ad01-e58fa6d96100",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # POSSIBLE METRICS FOR RANDOMIZEDSEARCHCV\n",
    "# import sklearn.metrics\n",
    "# sklearn.metrics.SCORERS.keys()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9b6ecaac-23ee-47b2-a465-7161b0168c96",
   "metadata": {},
   "source": [
    "z cross validae leze spise validacni error (Vašata)\n",
    "\n",
    "balancovaný dataset (zmínit)\n",
    "\n",
    "ROC krivky, recall, precision, F1, confusion matrix 3x3\n",
    "\n",
    "pro kazdy soubot natrenovat jiny model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "58a22117-b135-426a-9c5d-521d1b89a822",
   "metadata": {},
   "outputs": [],
   "source": [
    "import joblib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "85916d77-cea8-4d72-8625-c7ac7f6647f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# train_size = 150\n",
    "# test_size = 50\n",
    "# measures = []\n",
    "# for Path in Paths:\n",
    "#     print(Path)\n",
    "#     # X, y = LoadData(Path + \"/encoded.txt\")\n",
    "# #     X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.4, random_state = RANDOM_STATE)\n",
    "    \n",
    "# #     #smaller_sample\n",
    "# #     X_tr, y_tr =  X_train[:train_size], y_train[:train_size]\n",
    "# #     X_te, y_te = X_test[:test_size], y_test[:test_size]\n",
    "\n",
    "#     # BestScores = TryClassifiers(model_grid, RANDOM_STATE, X_tr, y_tr)\n",
    "#     model = PickBest(BestScores)\n",
    "#     # save model\n",
    "#     filename = '/classification_model.sav'\n",
    "#     joblib.dump(model, Path + filename)\n",
    "    \n",
    "#     exon_vs_rest_f1_score_ = FitPredictGetMetrics(model, X_te, y_te)\n",
    "#     measures.append(exon_vs_rest_f1_score_)\n",
    "#     # ROCAUCcurve(model, X_tr, y_tr, X_te, y_te)\n",
    "        \n",
    "#     break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "d73901b7-d3e8-4754-b00f-e62d607bfcb7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# measures"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2a1f6ff5-154f-46d2-a867-2d8affedcf4a",
   "metadata": {},
   "source": [
    "## Load any model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "d6d251e9-c9fd-4900-909b-8da9afb20613",
   "metadata": {},
   "outputs": [],
   "source": [
    "# filename = Path + '/classification_model.sav'\n",
    "\n",
    "# # load the model from disk\n",
    "# loaded_model = joblib.load(filename)\n",
    "# # result = loaded_model.score(X_te, y_te)\n",
    "# print(loaded_model)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "355e0912-98f1-4e23-87b2-c5cd5b10fc2c",
   "metadata": {},
   "source": [
    "## Results for 150k lines. With ROC curves"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "035f3094-00a2-4056-a9a1-40999c01ad34",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Paths[3:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fbc0b38f-8641-425c-b8b3-0157fdf7298e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/lieberze/DP/Thesis/tokenizery_new_data/data/sample/Encoding/Encoded_512bp_1M_lines/NEW/ByteLevelBPE/All_512/5000\n",
      "Fitting 5 folds for each of 5 candidates, totalling 25 fits\n",
      "Fitting 5 folds for each of 5 candidates, totalling 25 fits\n",
      "Fitting 5 folds for each of 4 candidates, totalling 20 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/lieberze/.conda/envs/bio/lib/python3.6/site-packages/sklearn/model_selection/_search.py:289: UserWarning: The total space of parameters 4 is smaller than n_iter=5. Running 4 iterations. For exhaustive searches, use GridSearchCV.\n",
      "  % (grid_size, self.n_iter, grid_size), UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GradientBoostingClassifier(max_depth=8, max_features='sqrt',\n",
      "                           min_samples_leaf=100, min_samples_split=3000,\n",
      "                           random_state=42, subsample=0.8)\n",
      "validation f1_score (weighted): 0.41271801036612565\n"
     ]
    }
   ],
   "source": [
    "train_size = 150000\n",
    "test_size = 50000\n",
    "measures = []\n",
    "for Path in Paths[3:]:\n",
    "    print(Path)\n",
    "    X, y = LoadData(Path + \"/encoded.txt\")\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.4, random_state = RANDOM_STATE)\n",
    "    \n",
    "    #smaller_sample\n",
    "    X_tr, y_tr =  X_train[:train_size], y_train[:train_size]\n",
    "    X_te, y_te = X_test[:test_size], y_test[:test_size]\n",
    "\n",
    "    BestScores = TryClassifiers(model_grid, RANDOM_STATE, X_tr, y_tr)\n",
    "    model = PickBest(BestScores)\n",
    "    \n",
    "    # save model\n",
    "    filename = '/classification_model.sav'\n",
    "    joblib.dump(model, Path + filename)\n",
    "    \n",
    "    weighted_f1_average_ = FitPredictGetMetrics(model, X_te, y_te, Path)\n",
    "    measures.append(weighted_f1_average_)\n",
    "    \n",
    "    ROCAUCcurve(model, X_tr, y_tr, X_te, y_te, Path)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "043c755e-36d5-4eed-845c-b38ec750743d",
   "metadata": {},
   "source": [
    "## Continue the computation (it stopped again)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "42663f77-37c3-404b-8665-c516a2a49ea4",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Load saved model\n",
    "classification_model.sav"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b6bcad7-606c-448a-9e89-cca3317456e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# for Path in Paths:\n",
    "#     print(Path + \"/classification_model.sav\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "717da9de-9f3d-4937-9e3e-d42746156ebc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# train_size = 150000\n",
    "# test_size = 50000\n",
    "# measures = []\n",
    "# for Path in Paths[1:]:\n",
    "#     print(Path)\n",
    "#     X, y = LoadData(Path + \"/encoded.txt\")\n",
    "#     X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.4, random_state = RANDOM_STATE)\n",
    "    \n",
    "#     #smaller_sample\n",
    "#     X_tr, y_tr =  X_train[:train_size], y_train[:train_size]\n",
    "#     X_te, y_te = X_test[:test_size], y_test[:test_size]\n",
    "    \n",
    "#     # load model\n",
    "#     model = joblib.load(Path + \"/classification_model.sav\")\n",
    "#     print(model)\n",
    "    \n",
    "#     exon_vs_rest_f1_score_ = FitPredictGetMetrics(model, X_te, y_te, Path)\n",
    "#     measures.append(exon_vs_rest_f1_score_)\n",
    "    \n",
    "#     ROCAUCcurve(model, X_tr, y_tr, X_te, y_te, Path)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c8e01acd-d520-4d42-92f2-6a1dd045c344",
   "metadata": {},
   "source": [
    "## Pick the best score (tokenizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fff00557-5522-4c0f-80d5-5393eb505873",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # how to evaluate? look at the ratio (measures[2])?\n",
    "# for p, m in zip(Paths, measures):\n",
    "#     print(p)\n",
    "#     print(m)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2514672f-92eb-46cc-a077-0283e72c6223",
   "metadata": {},
   "outputs": [],
   "source": [
    "# new_measures = []\n",
    "# for p, m in zip(Paths, measures):\n",
    "#     X = \"-\".join(p.split(\"/\")[-3:])\n",
    "#     new_measures.append([X, m])\n",
    "# new_measures"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "107fe7ac-4c2f-4c3e-8b26-a874345a4935",
   "metadata": {},
   "outputs": [],
   "source": [
    "# measures\n",
    "# zprumerovat do diplomky(?)\n",
    "# vzit neco z 512 bp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "808d7b1b-9dd3-4ad1-8d11-f1a136456cac",
   "metadata": {},
   "outputs": [],
   "source": [
    "# sorted_by_third = sorted(new_measures, key=lambda tup: tup[1][2], reverse=True)\n",
    "# sorted_by_third"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d1ce4520-b628-415f-baa1-643c94f16207",
   "metadata": {},
   "source": [
    "## Show saved results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "28fe8b98-75c9-4633-b536-b84c8e020c1e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle as pkl\n",
    "from PIL import Image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc49407a-cea2-4083-9753-78b22bac99b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "avgs = []\n",
    "for Path in Paths:\n",
    "    print(Path)\n",
    "    with open(Path + '/report.pkl', 'rb') as f:\n",
    "        report = pickle.load(f)\n",
    "        \n",
    "    # print(report)    \n",
    "    w_a = report[\"f1-score\"][\"weighted avg\"]\n",
    "    print(report)\n",
    "    avgs.append( [Path, w_a])\n",
    "          \n",
    "    conf_m = Image.open(Path + '/confusion_matrix.png')\n",
    "    roc = Image.open(Path + '/ROC_curve.png')\n",
    "    \n",
    "    conf_m.show()\n",
    "    roc.show() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce4ea4c8-83e1-4e13-a2f5-517b4e869924",
   "metadata": {},
   "outputs": [],
   "source": [
    "avgs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf448d0a-73de-4463-8b18-60f65b568062",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
