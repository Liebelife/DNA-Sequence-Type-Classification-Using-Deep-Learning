{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "9efd8465-9f12-47d5-9b58-56881800ca7a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install adapter-transformers\n",
    "# !pip install torch\n",
    "# !pip install pandas\n",
    "# !pip install keras\n",
    "# !pip install datasets\n",
    "# !pip install tensorflow\n",
    "# !pip install sklearn\n",
    "# !pip install wandb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e72cbde2-ea8c-4228-937e-34115b18c8d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "data_path = \"/home/lieberze/DP/Thesis/model_training/data/512_bp_for_encoding/All_equal_shuffled_100k.txt\"       \n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "cbbe61dc-2f5b-4950-9863-41882fc3a7af",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "file /home/lieberze/DP/Thesis/tokenizery_2_attempt/02_ByteLevelBPE/All_genomes_sample/All_512/5000/config.json not found\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "5000"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# https://huggingface.co/docs/tokenizers/python/latest/api/reference.html#module-tokenizers.processors\n",
    "from tokenizers import ByteLevelBPETokenizer\n",
    "from tokenizers import Tokenizer\n",
    "\n",
    "path = \"/home/lieberze/DP/Thesis/tokenizery_2_attempt/02_ByteLevelBPE/All_genomes_sample/All_512/5000/\"\n",
    "tokenizer = ByteLevelBPETokenizer(\n",
    "    path + \"vocab.json\",\n",
    "    path + \"merges.txt\",\n",
    ")\n",
    "\n",
    "# https://huggingface.co/docs/transformers/preprocessing\n",
    "from tokenizers.processors import BertProcessing\n",
    "tokenizer._tokenizer.post_processor = BertProcessing(\n",
    "    (\"</s>\", tokenizer.token_to_id(\"</s>\")),\n",
    "    (\"<s>\", tokenizer.token_to_id(\"<s>\"))\n",
    ")\n",
    "\n",
    "tokenizer.save(\"byte-level-bpe.tokenizer.json\", pretty=True)\n",
    "\n",
    "from transformers import RobertaTokenizer\n",
    "tokenizer = RobertaTokenizer.from_pretrained(path)\n",
    "tokenizer.vocab_size"
   ]
  },
  {
   "cell_type": "raw",
   "id": "432bf577-176d-44e9-8e01-1ff4ae216147",
   "metadata": {},
   "source": [
    "vracet input_ids, attention_mask, labels (musi se to takhle jmenovat)\n",
    "dataset ma metodu set_format (columns, ...)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ab778e49-bd75-48e6-8568-dbc083c6a9d1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "({0: 'exon', 1: 'intron', 2: 'intergenic'},\n",
       " {'exon': 0, 'intron': 1, 'intergenic': 2})"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "id2label = {id:label for id, label in enumerate([\"exon\", \"intron\", \"intergenic\"])}\n",
    "label2id = {label:id for id,label in id2label.items()}\n",
    "id2label, label2id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "c5b7bffc-3303-431f-9125-7d1d2287afc5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# a = \"exon\"\n",
    "# label2id[a]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "74b9681a-fbd2-4d7c-87be-a00dd8dc7f10",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import pandas as pd\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from keras.preprocessing.sequence import pad_sequences\n",
    "from torch.nn.utils.rnn import pad_sequence\n",
    "from datasets import load_dataset\n",
    "\n",
    "# defining the Dataset class\n",
    "class data_set(Dataset):\n",
    "    def __init__(self, data, labels, tokenizer):\n",
    "        self.data = data\n",
    "        self.labels = labels\n",
    "        self.tokenizer = tokenizer\n",
    "        \n",
    "    def __len__(self):\n",
    "        return len(self.data)\n",
    "    \n",
    "    def __getitem__(self, index):\n",
    "        seq = self.data[index]\n",
    "        lab = self.labels[index]\n",
    "        lab_id = label2id[lab]\n",
    "        tokenized = tokenizer(seq, max_length=128, padding=\"max_length\", truncation=True)   \n",
    "        tokenized_with_label = tokenized\n",
    "        tokenized_with_label[\"labels\"] = lab_id\n",
    "        return tokenized_with_label\n",
    "    \n",
    "df = pd.read_csv(data_path, sep=\"\\t\", names=['type','sequence'])\n",
    "dataset = data_set(df[\"sequence\"],df[\"type\"], tokenizer)\n",
    "\n",
    "dataloader = DataLoader(dataset, batch_size=4, shuffle=True) #, collate_fn=collate_tokenize) #, collate_fn=lambda x: x )\n",
    "data = next(iter(dataloader))\n",
    "# data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "9f4bc401-c82a-423b-a606-30840d574aa3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# for epoch in range(2):\n",
    "#     print(\"\\n==============================\\n\")\n",
    "#     print(\"Epoch = \" + str(epoch))\n",
    "#     for (batch_idx, batch) in enumerate(dataloader):\n",
    "#         print(\"\\nBatch = \" + str(batch_idx))\n",
    "#         print(batch)\n",
    "#         break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "dc0b9d9a-ab70-4a53-af6c-ce2016879d2c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "df_train, df_eval = train_test_split(df, test_size=0.25, random_state=42, stratify=df[\"type\"])\n",
    "df_train, df_holdout = train_test_split(df_train, test_size=0.1, random_state=42, stratify=df_train[\"type\"])\n",
    "\n",
    "df_train = df_train.reset_index()\n",
    "df_eval = df_eval.reset_index()\n",
    "df_holdout = df_holdout.reset_index()\n",
    "\n",
    "data_set_train = data_set(df_train[\"sequence\"],df_train[\"type\"], tokenizer)\n",
    "data_set_eval = data_set(df_eval[\"sequence\"],df_eval[\"type\"], tokenizer)\n",
    "# nesahat :)\n",
    "holdout_test = data_set(df_holdout[\"sequence\"],df_holdout[\"type\"], tokenizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "239c714d-b2c0-471e-a695-40e39eb4d889",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "total_optimization_steps: 1054.671875 \n",
      "how many 'eval_steps' to set: 105 \n",
      "how many steps in each evaluation stop: 65.10416666666667 \n",
      "hence in total: 6835.937500000001 steps for the whole evaluation\n"
     ]
    }
   ],
   "source": [
    "eval_size = len(df_eval)\n",
    "number_of_epochs = 6\n",
    "WANTED_eval_data_points_ratio = 0.1\n",
    "    # proportionally to the whole dataset size. e.g. 0.1 == 10% of all optimization\n",
    "    # steps is going to have an evaluation datapoint (loss)\n",
    "\n",
    "train_batch_size = eval_batch_size = 64\n",
    "total_optimization_steps = len(df_train)/train_batch_size\n",
    "eval_steps_in_one_run = eval_size/(number_of_epochs*train_batch_size)\n",
    "eval_steps_to_set=int(round(total_optimization_steps*WANTED_eval_data_points_ratio, 0))\n",
    "\n",
    "print(\"total_optimization_steps:\",total_optimization_steps,\n",
    "      \"\\nhow many 'eval_steps' to set:\",eval_steps_to_set,\n",
    "      \"\\nhow many steps in each evaluation stop:\",eval_steps_in_one_run,\n",
    "      \"\\nhence in total:\", eval_steps_to_set*eval_steps_in_one_run, \"steps for the whole evaluation\" )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "563baabc-0396-4295-88f1-fbead29fa756",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at roberta-trained_LR_0.0003_NEW were not used when initializing RobertaModelWithHeads: ['lm_head.dense.weight', 'lm_head.layer_norm.bias', 'lm_head.dense.bias', 'lm_head.bias', 'lm_head.layer_norm.weight']\n",
      "- This IS expected if you are initializing RobertaModelWithHeads from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing RobertaModelWithHeads from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of RobertaModelWithHeads were not initialized from the model checkpoint at roberta-trained_LR_0.0003_NEW and are newly initialized: ['roberta.pooler.dense.weight', 'roberta.pooler.dense.bias']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "from transformers import AdapterTrainer, AutoModelWithHeads #TrainingsArguments\n",
    "from transformers.training_args import TrainingArguments\n",
    "# https://docs.adapterhub.ml/training.html\n",
    "# https://discuss.huggingface.co/t/keyerror-loss-while-training-qna/4111\n",
    "# https://huggingface.co/docs/transformers/main_classes/trainer\n",
    "\n",
    "model = AutoModelWithHeads.from_pretrained('roberta-trained_LR_0.0003_NEW')\n",
    "adapter_name = \"sequence-classes-on_LR_3e-4_NEW_100k\"\n",
    "model.add_adapter(adapter_name)\n",
    "model.add_classification_head(adapter_name, num_labels=3, id2label = id2label) #, multilabel=False)\n",
    "model.train_adapter(adapter_name) # inicializace\n",
    "\n",
    "training_args =  TrainingArguments(\n",
    "    learning_rate=1e-4,\n",
    "    num_train_epochs=number_of_epochs,\n",
    "    report_to=\"wandb\",\n",
    "    output_dir = \"adapter_dir_NEW\",\n",
    "    label_names = [\"exon\", \"intron\", \"intergenic\"],\n",
    "    eval_steps = eval_steps_to_set, \n",
    "    evaluation_strategy=\"steps\",\n",
    "    per_device_train_batch_size=train_batch_size,\n",
    "    per_device_eval_batch_size=eval_batch_size,\n",
    ")\n",
    "\n",
    "from sklearn.metrics import accuracy_score\n",
    "from transformers import EvalPrediction\n",
    "def compute_acc(p: EvalPrediction):\n",
    "    preds, labels = p\n",
    "    acc = accuracy_score(labels, preds)\n",
    "    return {\"acc\": acc}\n",
    "\n",
    "model.metrics=['accuracy'] #optimizer=opt, loss=loss,\n",
    "\n",
    "trainer = AdapterTrainer(\n",
    "        model=model,\n",
    "        args=training_args,\n",
    "        train_dataset=data_set_train,\n",
    "        eval_dataset=data_set_eval,\n",
    "        compute_metrics = compute_acc,\n",
    "        # tokenizer=tokenizer, # data uz jsou ztokenizovana, netreba\n",
    "        # collator netreba\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d591da6e-02c4-4f10-808b-0fe04b3012fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "# for batch in trainer.get_train_dataloader():\n",
    "#     break\n",
    "# batch = {k: v.cuda() for k, v in batch.items()}\n",
    "# outputs = trainer.model(**batch)\n",
    "# batch, outputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "27280335-1fc9-4a2b-94e9-14712598aa34",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "***** Running training *****\n",
      "  Num examples = 67499\n",
      "  Num Epochs = 6\n",
      "  Instantaneous batch size per device = 64\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 192\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 2112\n",
      "Automatic Weights & Biases logging enabled, to disable set os.environ[\"WANDB_DISABLED\"] = \"true\"\n",
      "Failed to detect the name of this notebook, you can set it manually with the WANDB_NOTEBOOK_NAME environment variable to enable code saving.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mliebelife\u001b[0m (use `wandb login --relogin` to force relogin)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "                    Syncing run <strong><a href=\"https://wandb.ai/liebelife/huggingface/runs/2qjzummp\" target=\"_blank\">adapter_dir_NEW</a></strong> to <a href=\"https://wandb.ai/liebelife/huggingface\" target=\"_blank\">Weights & Biases</a> (<a href=\"https://docs.wandb.com/integrations/jupyter.html\" target=\"_blank\">docs</a>).<br/>\n",
       "\n",
       "                "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/lieberze/.conda/envs/dp/lib/python3.6/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='75' max='2112' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [  75/2112 04:41 < 2:10:57, 0.26 it/s, Epoch 0.21/6]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "trainer.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12d0011f-34a0-4d1a-a8c2-b4f620a3dedd",
   "metadata": {},
   "outputs": [],
   "source": [
    "trainer.save_model(\"adapter-sequence-types-NEW\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "8964565a-8722-425c-b437-51cfc11b3071",
   "metadata": {},
   "outputs": [],
   "source": [
    "# model.save_adapter(\"./adapter-sequence-types/\", adapter_name) # jen adapter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "ec998f08-617d-4313-a49a-61ff76195d2c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# pak mu dam holdout a udelam confusion matrix, model.predict. vyvazeny data\n",
    "# list s predikcema, true values a pak conf_matice"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "649321af-0340-438b-ba1a-6d2570fbcd25",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = AutoModelWithHeads.from_pretrained(\"roberta-trained_LR_0.0003_NEW\")\n",
    "tokenizer = tokenizer\n",
    "\n",
    "adapter1 = model.load_adapter(\"adapter-sequence-types-NEW/sequence-classes-on_LR_3e-4_NEW_100k\")\n",
    "\n",
    "# model.active_adapters = ac.Parallel(adapter1)\n",
    "model.active_adapters = adapter1\n",
    "\n",
    "# input_ids = tokenizer(a, return_tensors=\"pt\")\n",
    "# print(\"STS-B adapter output:\", output1)\n",
    "# print(\"MRPC adapter output:\", bool(torch.argmax(output1[0]).item()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "c9cb55a9-787d-4168-bd67-f5d6b8215caa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# wandb.finish()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "757ba8e7-fc61-46b1-b283-e9b62a049fc0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import transformers.adapters.composition as ac\n",
    "# model = AutoModelWithHeads.from_pretrained('roberta-trained')\n",
    "# model.add_adapter(\"adapter-sequence-types\")\n",
    "# model.active_adapters = ac.Stack(\"adapter-sequence-types\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "9c7144c8-a035-48d1-88a7-2571b3fc02bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# model.to(\"cuda:0\")\n",
    "# trainer.evaluate()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4f3b96a0-7d22-4866-8e39-e40a9aae0fe9",
   "metadata": {},
   "source": [
    "training_args.device.indexhttps://github.com/NielsRogge/Transformers-Tutorials/blob/master/VisionTransformer/Fine_tuning_the_Vision_Transformer_on_CIFAR_10_with_the_%F0%9F%A4%97_Trainer.ipynb\n",
    "\n",
    "hlavne konec - evaluace a confusion matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "7e62093f-387a-4902-8a60-fa3fc5fdb92c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import TextClassificationPipeline\n",
    "classifier = TextClassificationPipeline(model=model, tokenizer=tokenizer, device=training_args.device.index)\n",
    "# classifier(a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "d94aac40-f4cf-4c89-af06-2200e9282e1d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# model.to(torch.device(\"cuda:0\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "08fad48f-77f9-4e4a-8750-8d95d92a8837",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/lieberze/.conda/envs/dp/lib/python3.6/site-packages/torch/utils/data/dataloader.py:481: UserWarning: This DataLoader will create 8 worker processes in total. Our suggested max number of worker in current system is 4, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
      "  cpuset_checked))\n"
     ]
    }
   ],
   "source": [
    "sequences = list(df_holdout.sequence)\n",
    "true_labels = list(df_holdout.type)\n",
    "pred_labels = classifier(sequences)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "a16b3268-55b8-48fc-a2e2-7937083fef18",
   "metadata": {},
   "outputs": [],
   "source": [
    "# pred_labels = []\n",
    "# for sequence in sequences:\n",
    "#     pred_label = classifier(sequence)\n",
    "#     pred_labels.append(pred_label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "3e1043fa-9c8e-4631-b88e-c75a7a4b388b",
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_lab = [i[\"label\"] for i in pred_labels]\n",
    "pred_score = [i[\"score\"] for i in pred_labels]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "ab7b40f4-6de6-49a8-b08f-5085da924c02",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'label': 'exon', 'score': 0.9983795881271362},\n",
       " {'label': 'intergenic', 'score': 0.47173500061035156},\n",
       " {'label': 'intergenic', 'score': 0.4336871802806854},\n",
       " {'label': 'intergenic', 'score': 0.49356016516685486},\n",
       " {'label': 'intergenic', 'score': 0.4579002559185028},\n",
       " {'label': 'intergenic', 'score': 0.4834924638271332},\n",
       " {'label': 'intergenic', 'score': 0.670271098613739},\n",
       " {'label': 'intron', 'score': 0.5133808255195618},\n",
       " {'label': 'intron', 'score': 0.4452618658542633},\n",
       " {'label': 'intergenic', 'score': 0.6688063740730286},\n",
       " {'label': 'intron', 'score': 0.5226362347602844},\n",
       " {'label': 'intergenic', 'score': 0.7244045734405518},\n",
       " {'label': 'exon', 'score': 0.47243958711624146},\n",
       " {'label': 'intergenic', 'score': 0.5378977060317993},\n",
       " {'label': 'intron', 'score': 0.5387783646583557},\n",
       " {'label': 'intergenic', 'score': 0.48589691519737244},\n",
       " {'label': 'exon', 'score': 0.9897705316543579},\n",
       " {'label': 'intron', 'score': 0.5216395854949951},\n",
       " {'label': 'intergenic', 'score': 0.5391117334365845},\n",
       " {'label': 'intron', 'score': 0.521825909614563},\n",
       " {'label': 'intron', 'score': 0.37132689356803894},\n",
       " {'label': 'intergenic', 'score': 0.44733116030693054},\n",
       " {'label': 'exon', 'score': 0.9741964936256409},\n",
       " {'label': 'intron', 'score': 0.5696598887443542},\n",
       " {'label': 'exon', 'score': 0.9849441647529602},\n",
       " {'label': 'intergenic', 'score': 0.4113721251487732},\n",
       " {'label': 'intergenic', 'score': 0.48030558228492737},\n",
       " {'label': 'intron', 'score': 0.4317578971385956},\n",
       " {'label': 'exon', 'score': 0.3672199845314026},\n",
       " {'label': 'intron', 'score': 0.4986215829849243},\n",
       " {'label': 'intergenic', 'score': 0.4928617775440216},\n",
       " {'label': 'intergenic', 'score': 0.3857899010181427},\n",
       " {'label': 'intergenic', 'score': 0.6330037713050842},\n",
       " {'label': 'intergenic', 'score': 0.5593283176422119},\n",
       " {'label': 'intron', 'score': 0.4318796694278717},\n",
       " {'label': 'intergenic', 'score': 0.623039722442627},\n",
       " {'label': 'exon', 'score': 0.9982348680496216},\n",
       " {'label': 'intron', 'score': 0.4393635392189026},\n",
       " {'label': 'intergenic', 'score': 0.5059700608253479},\n",
       " {'label': 'intron', 'score': 0.4485228359699249},\n",
       " {'label': 'exon', 'score': 0.9912071824073792},\n",
       " {'label': 'intergenic', 'score': 0.47743844985961914},\n",
       " {'label': 'intron', 'score': 0.45148390531539917},\n",
       " {'label': 'intron', 'score': 0.4381657540798187},\n",
       " {'label': 'intron', 'score': 0.7476833462715149},\n",
       " {'label': 'exon', 'score': 0.5762860178947449},\n",
       " {'label': 'intron', 'score': 0.42347607016563416},\n",
       " {'label': 'exon', 'score': 0.9976110458374023},\n",
       " {'label': 'intron', 'score': 0.4967259168624878},\n",
       " {'label': 'exon', 'score': 0.9595978856086731}]"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pred_labels[:50]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f9f7e909-909b-4dc1-a6d0-0f6b41d9ebf7",
   "metadata": {},
   "source": [
    "tady je videt, ze jakmile je to exon, tak si je hodne jistej => nejspis se uci podle delky :/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "cb9ba0f6-c69e-46fb-8294-f777e5693d61",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "from sklearn import metrics\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "6ab91ecc-fd5d-406c-b3f3-1cef3b7a7e4a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{0: 'exon', 1: 'intron', 2: 'intergenic'}"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "id2label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "770ba66d-fdf1-4e29-8690-314a37932e96",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 576x432 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "cm = metrics.confusion_matrix(true_labels, pred_lab, normalize='true')\n",
    "\n",
    "# confusion matrix\n",
    "plt.figure(figsize=(8, 6))\n",
    "df_cm = pd.DataFrame(cm)\n",
    "df_cm.columns = ['exon', 'intron','intergenic']\n",
    "df_cm.index = ['exon', 'intron','intergenic']\n",
    "plt.title('Confusion Matrix, normalized', size=16)\n",
    "sns.heatmap(df_cm, annot=True, cmap='Blues')\n",
    "\n",
    "plt.savefig('100k-NEW-all.png')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "9fad4bf6-644f-4ac3-8dae-aceb29c32da2",
   "metadata": {},
   "outputs": [],
   "source": [
    "report = metrics.classification_report(true_labels, pred_lab, digits=2, output_dict=True, zero_division=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "f1c83854-7543-4c30-8718-05db7a27a874",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision  recall  f1-score    support\n",
      "exon           0.887850  0.7600  0.818966  2500.0000\n",
      "intergenic     0.539610  0.5640  0.551535  2500.0000\n",
      "intron         0.488897  0.5372  0.511912  2500.0000\n",
      "accuracy       0.620400  0.6204  0.620400     0.6204\n",
      "macro avg      0.638786  0.6204  0.627471  7500.0000\n",
      "weighted avg   0.638786  0.6204  0.627471  7500.0000\n"
     ]
    }
   ],
   "source": [
    "df_report = pd.DataFrame(report).transpose()\n",
    "df_report\n",
    "# SHOW THE DIFFERENCES\n",
    "exon, intron, intergenic = df_report[\"f1-score\"].exon, df_report[\"f1-score\"].intron, df_report[\"f1-score\"].intergenic\n",
    "exon_vs_rest_ratio = exon/(intron + intergenic)\n",
    "exon_vs_rest_f1_score = exon, intron + intergenic, exon_vs_rest_ratio\n",
    "print(df_report)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "3ffd6cba-1bd1-41ed-8361-dc95b8d1bfb7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ratio of exon vs rest success: 0.7701047789184546\n"
     ]
    }
   ],
   "source": [
    "exon_vs_rest_f1_score # (exon, intron+intergenic, their ratio)\n",
    "print(\"ratio of exon vs rest success:\", exon_vs_rest_f1_score[2]) # zamerujeme se na uspech predikce exonu"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c973efd3-0d36-4822-99bb-2073646e8091",
   "metadata": {},
   "source": [
    "u nestejne dlouhych - horsi nez ML modely = 0.77 (mely 0.81 az 0.83), ale ted, po uprave delek je to lepsi 0.86 (zkouseno na 20k vzorku)))))\n",
    "\n",
    "0.72 pro natrenovane na kratkych, ale adapter na 100k dlouhych\n",
    "0.77 pro natrenovane na kratkych a adapter taky na nich"
   ]
  },
  {
   "cell_type": "raw",
   "id": "dfed34c9-9272-417b-bf9f-86d61d1a985a",
   "metadata": {},
   "source": [
    "or"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "d4b3b596-e6fb-4e80-b91f-de92dde0491c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import wandb\n",
    "wandb.login()\n",
    "wandb.finish()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "a66ab65e-50b8-4d1b-824a-58182978e418",
   "metadata": {},
   "outputs": [],
   "source": [
    "# outputs = trainer.predict(test_ds) # test_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "9d82e0e3-a28e-4939-bf3e-496cdf056cd2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# from sklearn.metrics import confusion_matrix, ConfusionMatrixDisplay\n",
    "\n",
    "# y_true = outputs.label_ids\n",
    "# y_pred = outputs.predictions.argmax(1)\n",
    "\n",
    "# labels = train_ds.features['label'].names\n",
    "# cm = confusion_matrix(y_true, y_pred)\n",
    "# disp = ConfusionMatrixDisplay(confusion_matrix=cm, display_labels=labels)\n",
    "# disp.plot(xticks_rotation=45)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "8eddb541-f524-44b3-935f-ea3d854fbe56",
   "metadata": {},
   "outputs": [],
   "source": [
    "# the correct way to predict with a trained model is prediction = model(tokenized_sequence_to_classify)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "88cb4484-f7c1-4544-ba44-de40a07b9b7e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# output1 = model(**input_ids)\n",
    "# torch.argmax(output1[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "3ced4455-a42c-488e-a90a-e1016075926f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# model.load_adapter('roberta-trained', \"./adapter-sequence-types/\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "8ae3902d-ab68-4552-a779-40e7e13fdbab",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import transformers.adapters.composition as ac"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "23e9e939-97d2-4a75-bd7e-e741566899f1",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# model.load_adapter(\"adapter-sequence-types\")\n",
    "# model.set_active_adapters(\"adapter-sequence-types\")\n",
    "# model.predict() # pozor! asi potreba male batche, test set (holdout)\n",
    "# asi bude potreba pushnout data na gpu rucne:\n",
    "# model.to(\"cuda\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "a9eeb6cf-3ac6-4d09-8c43-676e21836e24",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# #initializing the model\n",
    "# model = MLP().to(device)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
